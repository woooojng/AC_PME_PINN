{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0557ffda-0ae1-40d8-a916-ad933fbb8890",
   "metadata": {},
   "source": [
    "## Porous Medium Equation Solver Result Summary (1D)\n",
    "\n",
    "**Woojeong Kim** *7/30/2025*\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc70b61-8b8e-43af-8857-70821e080b3b",
   "metadata": {},
   "source": [
    "### Porous Medium Equation\n",
    "The **porous medium equation** is also called as **non-linear heat equation** and  has the form on 1-dimensional domain:\n",
    "$$\n",
    "\\frac{\\partial u(x,t)}{\\partial t} = \\Delta u(x,t)^m , \\text{~ where ~} m > 0 \\text{~and~} x \\in \\Omega.\n",
    "$$\n",
    "Main driving force of this equation is Energy term - i.e, the output solution variable $u$ behaves mainly by Energy of the form:\n",
    "$$\n",
    "E(u) = \\int_{\\Omega} u^m du\n",
    "$$\n",
    "To analyze the Energy, we take derivative as:\n",
    "$$\n",
    "\\frac{d E(u)}{dx} = m u^{m-1}u_x \n",
    "$$\n",
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../Heat/Energy_adaptive_std.075/exact_solution.png\" width=\"750\"/><br/>\n",
    "      <small>Figure 1.2: Energy adaptive</small>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede071d-bbae-4161-9834-534030c7924b",
   "metadata": {},
   "source": [
    "### Barenblatt-Kompaneets-Zeldovich similarity solution\n",
    "The exact solution named as `Barenblatt-Kompaneets-Zeldovich solution` has the form:\n",
    "$$\n",
    "u_{\\text{exact}}(x, t) = \\frac{1}{t^\\alpha} \\left( b - \\frac{m-1}{2m} \\beta \\frac{\\| x \\|^2}{t^{2\\beta}} \\right) _{+}^{\\frac{1}{m-1}}\n",
    "$$\n",
    "where $x \\in \\mathbb{R}^n$, $\\| \\cdot \\|^2$ is the $l^2$- norm, $(\\cdot)_+$ is the positive part, and\n",
    "$$\n",
    "\\alpha = \\frac{n}{n(m-1) +2}, ~~~~\\beta = \\frac{1}{n(m-1)+2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262c507-017b-4e30-b762-98e3d7172245",
   "metadata": {},
   "source": [
    "### Physics-Informed Neural Network Loss Term\n",
    "As the preliminary famework for building PINN, we use the following loss terms to optimize total loss by `.backward()` at the end of each training iteration. The 1-dimensional spatial domain $\\Omega := [-5, 5]$ and time domain is $[0,T]$ where $T$ is ending time.\n",
    "- Loss on domain\n",
    "  $$\n",
    "  L_{p} = u(x,t)_tt - u(x,t)^m, ~~~~ (x, t) \\in [-5, 5] \\times [0, T]\n",
    "  $$\n",
    "- Loss derived from initial condition\n",
    "  $$\n",
    "  L_i = u_{\\text{exact}}(x,.01),  ~~~~ x \\in [-5, 5]\n",
    "  $$\n",
    "- Loss derived from boundary condition - periodic boundary\n",
    "  $$\n",
    "  L_{b1} = u(-5,t) - u(5,t)\n",
    "  $$\n",
    "  $$\n",
    "  {L}_{b2} = u_x(-5,t) - u_x(5,t),  ~~~~ t \\in [0, T]\n",
    "  $$\n",
    "And, the basic total loss is set as follows.\n",
    "$$\n",
    "\\implies L_t = L_{p} + 1000 L_i + L_{b1} + L_{b2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b8228-94fd-4123-b9ec-64c774414e8e",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "This is the base line experiment using the basic total loss $L_t$. In this notebook we use 6 hidden layers with neuron size 100 for the `forward` pass of the neural network and `torch.tanh`activation function on each layer. In this experiment, 12000, 150 and 200 collocation points collocation points were used for computing $L_p$, $L_{b1}+{L}_{b2}$ and $L_i$ respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42044c65-9abf-4888-b241-a24a73510e6f",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "This is the classical experiment for observing the efficiency of adaptive resampling. we splited the basic total loss $L_t$ into the basic loss term and resampled loss term according to the upper 10% high-loss points:\n",
    "$$\n",
    "\\implies L_t = L_{p1} + L_{p2} + 1000 (L_{i1} + L_{i2}) + L_{b1} + L_{b2}\n",
    "$$\n",
    "where $L_{p1} = L_{p}$, $L_{i1} = L_{i}$. And, $L_{p2}$, $L_{i2}$ are pde loss term and initial loss term from the high-loss resampling for the upper 10% from each term. The collocation points numbers are 8000 for $L_{p1}$, 4000 for $L_{p2}$, 150 for $L_{i1}$, 50 for $L_{i2}$ and 150 for $L_{b1} + L_{b2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d95a1-5866-4733-9393-ce3779d12cd4",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "This is the new resampling method in MCMC process, **likelihood-free MCMC**, which is inspired by Metropolis Hasting and probability density approximation to the gradient of eneery $\\frac{\\partial E}{\\partial x}$. By employing this method, we give more training collocation points on the rapidley changing domain area powered by fast change of energy value. Similar to the Experiment2, to compare this with the previous experiment, we splited the basic total loss $L_t$ in experiment 1 into the basic loss term and loss term resampled from this likelihood-free MCMC:\n",
    "$$\n",
    "\\implies L_t = L_{p1} + 100L_{p3} + 1000 (L_{i1} + L_{i3}) + L_{b1} + L_{b2}\n",
    "$$\n",
    "where $L_{p1} = L_{p}$, $L_{i1} = L_{i}$. And, $L_{p3}$, $L_{i3}$ are pde loss term and initial loss term from the likelihood-free MCMC. The collocation points numbers are 8000 for $L_{p1}$, 4000 for $L_{p3}$, 150 for $L_{i1}$, 50 for $L_{i3}$ and 150 for $L_{b1} + L_{b2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cc8b5-f1fb-442a-b2a1-2d6f9ea9d78c",
   "metadata": {},
   "source": [
    "### Algorithm: Likelihodd-Free MCMC(LF Metropolis-Hastings) sampling\n",
    "\n",
    "We are given data $\\theta = {\\theta_1, \\theta_2, ..., \\theta_n}$ considered as likelihood of $x = {x_1, x_2, ..., x_n}$. We assume that the likelihood $\\theta$ is generalized as $x$ by using KDE likelihood on $\\theta$ and neighborhood points for each of $\\theta$. With this condition, we will accept or reject proposal $(\\theta', x')$ by using acceptance ratio $\\alpha$ where $\\theta' = {\\theta_1', \\theta_2', ..., \\theta_n'}$. Since $\\theta :=  From the current algorithm sate $(\\theta, x)$, a new parameter vetor $\\theta '$ is drawn from a proposal distribution $q(\\theta ' | \\theta)$.\n",
    "\n",
    "**Input**:  \n",
    "- Target distribution $\\pi(x, t) := |u(x, t) u_x(x, t)|$ (Normalized $\\frac{d E(u)}{dx} = m u^{m-1}u_x$)  \n",
    "- Proposal distribution $q(x' | x) ~ N(\\pi(x,t), 0.075)$  \n",
    "- Initial value $x_0 := \\pi (x,0)$  \n",
    "- Total number of approximating sampling iterations $N := 75$\n",
    "\n",
    "**Output**:  \n",
    "- Samples $\\hat{\\theta} = {\\hat{\\theta}_1, \\hat{\\theta}_2, ..., \\hat{\\theta}_n}$ approximating $\\pi(x, t)$\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. Initialize k = 1 and observed data y  ← $\\pi(\\theta)$ from given $\\theta$  \n",
    "2. For step $k$ with given $(\\theta_{k},x_{k}) = (\\theta,x)$:\n",
    "    - (1) Extract generalized simulation data $x_i$ ←  $\\pi( B )$ for i = 1,2,...,n where B := {100 points in the closed disk centered $\\theta_i$ with radius 0.25}.  \n",
    "    - (2) Generate $\\theta'$ ∼ $q( \\theta' | \\theta)$\n",
    "    - (3) Similar to (1), generate generalized simulation data $x_i'$ ← $\\pi( B' )$ for i = 1,2,...,n where B' := {100 points in the closed disk centered $\\theta_i'$ with radius 0.25}.\n",
    "    - (4) Compute acceptance ratio:  \n",
    "      $$ \\alpha = \\min\\left(1, \\frac{\\pi_{\\epsilon}(y|x', \\theta') \\pi(\\theta')q(\\theta | \\theta')}{\\pi_{\\epsilon}(y|x, \\theta) \\pi(\\theta)q(\\theta' | \\theta)}\\right) $$\n",
    "      where $\\pi_{\\epsilon}(y|x, \\theta) = 1$ where $|\\text{KDE}(y, x)| < \\epsilon$, 0 otherwise for KDE() function computing KDE likelihood for a query y against group x of 100 neighborhood points of the query $\\theta$.\n",
    "    - (5) With probability $\\alpha$, accept $(\\theta_{k+1},x_{k+1}) = (\\theta', x')$ ; else, keep $(\\theta,x)$.\n",
    "3. Increment $k = k+1$ and go to 2. until $k = 75$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5e2ce-eaf4-46bb-ba53-5751a059bd9e",
   "metadata": {},
   "source": [
    "### Resampling Figures for each end time in time slice\n",
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Loss_adaptive/2by10_adap.png\" width=\"750\"/><br/>\n",
    "      <small>Figure 2: Loss adaptive</small>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Energy_adaptive_std.075/Energy_adaptive_MCMC_resampling_each_time.png\" width=\"750\"/><br/>\n",
    "      <small>Figure 3: Energy adaptive</small>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b6d62-7da5-4558-96fc-d6aa34ff940f",
   "metadata": {},
   "source": [
    "### Plot Results\n",
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Loss_adaptive/3D_7_25_18h_end1.2.png\" width=\"750\"/><br/>\n",
    "      <small>Figure 1.1: Loss adaptive</small>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Energy_adaptive_std.075/3D_7_28_7h_end1.2.png\" width=\"750\"/><br/>\n",
    "      <small>Figure 1.2: Energy adaptive</small>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Loss_adaptive/2D_7_25_18h_end1.2_2d.png\" width=\"850\"/><br/>\n",
    "      <small>Figure 2.1: Loss adaptive</small>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"Energy_adaptive_std.075/2D_7_28_7h_end1.2_2d.png\" width=\"850\"/><br/>\n",
    "      <small>Figure 2.2: Energy adaptive</small>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee88ab1-5714-4cd6-b123-e4b224b5c7bd",
   "metadata": {},
   "source": [
    "### Error Value Results\n",
    "\n",
    "| Error Type        | Experiment 1 : Baseline | Experiment 2 : Loss Adpative | Experiment 3 : Energy Adpative |\n",
    "|-------------------|--------------------|--------------------|--------------------|\n",
    "| L∞ L∞ Error (u)      | value₁₁           | 0.46           | 0.44          |\n",
    "| L∞ Error (u)     | value₂₁           | 0.002141  (relative 0.020912)      | 0.001767  (relative 0.017264) |\n",
    "| L2 Error (u)      | value₃₁           |  0.002421 (relative 0.016163) | 0.002047 (relative 0.013662) |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b4c7d-7c29-43dd-b643-1cf88177cced",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Porous_medium_equation  \n",
    "[2] Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng (eds.). *Handbook of Markov Chain Monte Carlo*. Chapman & Hall/CRC, 2011.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d91f22-7172-43f6-aff8-60d8c32e4ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mydev-env)",
   "language": "python",
   "name": "mydev-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
